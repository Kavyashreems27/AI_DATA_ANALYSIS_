{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyONz4In0hkHVv8lBYvvWSVC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","import unittest\n","\n","def preprocess_data(df, target_column=None):\n","    \"\"\"\n","    Applies a comprehensive set of data preprocessing steps to the input DataFrame.\n","    Includes rigorous type checking and handles potential errors.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame to preprocess.\n","        target_column (str, optional): The name of the target variable column.\n","                                       If provided, it will be separated before preprocessing\n","                                       and rejoined at the end. Defaults to None.\n","\n","    Returns:\n","        tuple: A tuple containing the preprocessed features (pd.DataFrame) and\n","               the target variable (pd.Series) if target_column is provided,\n","               otherwise just the preprocessed features (pd.DataFrame).\n","\n","    Raises:\n","        TypeError: If the input 'df' is not a pandas DataFrame.\n","        ValueError: If 'target_column' is not found in the DataFrame.\n","    \"\"\"\n","    if not isinstance(df, pd.DataFrame):\n","        raise TypeError(\"Input 'df' must be a pandas DataFrame.\")\n","\n","    X = df.copy()\n","    y = None\n","    if target_column is not None:\n","        if target_column not in X.columns:\n","            raise ValueError(f\"Target column '{target_column}' not found in DataFrame.\")\n","        y = X[target_column]\n","        X = X.drop(columns=[target_column])\n","\n","    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n","    categorical_cols = X.select_dtypes(include='object').columns.tolist()\n","\n","    numerical_transformer = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='median')),\n","        ('scaler', StandardScaler())\n","    ])\n","\n","    categorical_transformer = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='most_frequent')),\n","        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","    ])\n","\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_cols),\n","            ('cat', categorical_transformer, categorical_cols)])\n","\n","    try:\n","        X_processed = preprocessor.fit_transform(X)\n","        feature_names = preprocessor.get_feature_names_out(input_features=X.columns)\n","        X_processed_df = pd.DataFrame(X_processed, columns=feature_names, index=X.index)\n","    except Exception as e:\n","        raise RuntimeError(f\"Error during preprocessing: {e}\")\n","\n","    if y is not None:\n","        return X_processed_df, y\n","    else:\n","        return X_processed_df\n","\n","def handle_outliers_iqr(df, columns, threshold=1.5):\n","    \"\"\"\n","    Handles outliers in specified numerical columns of a DataFrame using the IQR method.\n","    Includes type and value checks, and handles cases where columns might not exist.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame.\n","        columns (list): A list of column names to handle outliers in.\n","        threshold (float): The multiplier for the IQR to define outlier boundaries.\n","\n","    Returns:\n","        pd.DataFrame: The DataFrame with outliers capped at the IQR boundaries.\n","\n","    Raises:\n","        TypeError: If 'df' is not a pandas DataFrame or 'columns' is not a list.\n","        ValueError: If 'threshold' is not a positive number.\n","    \"\"\"\n","    if not isinstance(df, pd.DataFrame):\n","        raise TypeError(\"Input 'df' must be a pandas DataFrame.\")\n","    if not isinstance(columns, list):\n","        raise TypeError(\"Input 'columns' must be a list.\")\n","    if not isinstance(threshold, (int, float)) or threshold <= 0:\n","        raise ValueError(\"Input 'threshold' must be a positive number.\")\n","\n","    df_cleaned = df.copy()\n","    for col in columns:\n","        if col in df_cleaned.columns:\n","            if pd.api.types.is_numeric_dtype(df_cleaned[col]):\n","                Q1 = df_cleaned[col].quantile(0.25)\n","                Q3 = df_cleaned[col].quantile(0.75)\n","                IQR = Q3 - Q1\n","                lower_bound = Q1 - threshold * IQR\n","                upper_bound = Q3 + threshold * IQR\n","                df_cleaned[col] = np.where(df_cleaned[col] < lower_bound, lower_bound, df_cleaned[col])\n","                df_cleaned[col] = np.where(df_cleaned[col] > upper_bound, upper_bound, df_cleaned[col])\n","            else:\n","                print(f\"Warning: Column '{col}' is not numerical and outlier handling was skipped.\")\n","        else:\n","            print(f\"Warning: Column '{col}' not found in DataFrame.\")\n","    return df_cleaned\n","\n","def remove_duplicate_rows(df):\n","    \"\"\"\n","    Removes duplicate rows from a DataFrame.\n","    Includes type checking.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame.\n","\n","    Returns:\n","        pd.DataFrame: The DataFrame with duplicate rows removed.\n","\n","    Raises:\n","        TypeError: If the input 'df' is not a pandas DataFrame.\n","    \"\"\"\n","    if not isinstance(df, pd.DataFrame):\n","        raise TypeError(\"Input 'df' must be a pandas DataFrame.\")\n","    df_no_duplicates = df.drop_duplicates().reset_index(drop=True)\n","    return df_no_duplicates\n","\n","def handle_imbalanced_data(X, y, method='oversampling', random_state=None):\n","    \"\"\"\n","    Handles imbalanced datasets using either oversampling or undersampling.\n","    Includes type and value checks, and handles cases where the method is not recognized.\n","\n","    Args:\n","        X (pd.DataFrame): The feature matrix.\n","        y (pd.Series): The target variable.\n","        method (str): 'oversampling' or 'undersampling'. Defaults to 'oversampling'.\n","        random_state (int, optional): Random seed for reproducibility. Defaults to None.\n","\n","    Returns:\n","        tuple: The resampled feature matrix (pd.DataFrame) and target variable (pd.Series).\n","\n","    Raises:\n","        TypeError: If 'X' is not a pandas DataFrame or 'y' is not a pandas Series.\n","        ValueError: If 'method' is not 'oversampling' or 'undersampling'.\n","    \"\"\"\n","    if not isinstance(X, pd.DataFrame):\n","        raise TypeError(\"Input 'X' must be a pandas DataFrame.\")\n","    if not isinstance(y, pd.Series):\n","        raise TypeError(\"Input 'y' must be a pandas Series.\")\n","    if method not in ['oversampling', 'undersampling']:\n","        raise ValueError(\"Input 'method' must be either 'oversampling' or 'undersampling'.\")\n","\n","    if method == 'oversampling':\n","        smote = SMOTE(random_state=random_state)\n","        try:\n","            X_resampled, y_resampled = smote.fit_resample(X, y)\n","            return pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled)\n","        except Exception as e:\n","            raise RuntimeError(f\"Error during oversampling: {e}\")\n","    elif method == 'undersampling':\n","        rus = RandomUnderSampler(random_state=random_state)\n","        try:\n","            X_resampled, y_resampled = rus.fit_resample(X, y)\n","            return pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled)\n","        except Exception as e:\n","            raise RuntimeError(f\"Error during undersampling: {e}\")\n","\n","class TestDataPreprocessing(unittest.TestCase):\n","    def setUp(self):\n","        self.sample_data = pd.DataFrame({\n","            'numerical_col1': [1, 5, 2, np.nan, 7, 100, 3],\n","            'numerical_col2': [0.1, 0.5, 0.2, 0.8, np.nan, 0.3, 0.6],\n","            'categorical_col1': ['A', 'B', 'A', 'C', 'B', 'A', np.nan],\n","            'categorical_col2': ['X', 'Y', 'X', 'Z', 'Y', 'X', 'Y'],\n","            'target_variable': [0, 1, 0, 1, 0, 1, 0]\n","        })\n","\n","    def test_preprocess_data_type_error(self):\n","        with self.assertRaises(TypeError):\n","            preprocess_data(\"not a dataframe\")\n","\n","    def test_preprocess_data_target_not_found(self):\n","        with self.assertRaises(ValueError):\n","            preprocess_data(self.sample_data, target_column='non_existent_column')\n","\n","    def test_preprocess_data_output_shape(self):\n","        processed_X, y = preprocess_data(self.sample_data, target_column='target_variable')\n","        self.assertEqual(processed_X.shape[0], self.sample_data.shape[0])\n","        self.assertGreater(processed_X.shape[1], self.sample_data.drop(columns=['target_variable']).shape[1]) # Due to one-hot encoding\n","        self.assertEqual(y.shape[0], self.sample_data.shape[0])\n","\n","    def test_handle_outliers_iqr_type_error(self):\n","        with self.assertRaises(TypeError):\n","            handle_outliers_iqr(self.sample_data, \"not a list\")\n","        with self.assertRaises(TypeError):\n","            handle_outliers_iqr(\"not a dataframe\", ['numerical_col1'])\n","        with self.assertRaises(ValueError):\n","            handle_outliers_iqr(self.sample_data, ['numerical_col1'], 0)\n","\n","    def test_handle_outliers_iqr_column_not_found(self):\n","        df_modified = handle_outliers_iqr(self.sample_data.copy(), ['non_existent_column'])\n","        self.assertTrue(df_modified.equals(self.sample_data)) # Should return original if column not found\n","\n","    def test_handle_outliers_iqr_non_numerical_column(self):\n","        df_modified = handle_outliers_iqr(self.sample_data.copy(), ['categorical_col1'])\n","        self.assertTrue(df_modified.equals(self.sample_data)) # Should skip non-numerical\n","\n","    def test_remove_duplicate_rows_type_error(self):\n","        with self.assertRaises(TypeError):\n","            remove_duplicate_rows(\"not a dataframe\")\n","\n","    def test_remove_duplicate_rows_functionality(self):\n","        df_with_duplicates = pd.concat([self.sample_data, self.sample_data.iloc[[0]]]).reset_index(drop=True)\n","        df_unique = remove_duplicate_rows(df_with_duplicates)\n","        self.assertEqual(df_unique.shape[0], self.sample_data.shape[0])\n","\n","    def test_handle_imbalanced_data_type_error(self):\n","        X = self.sample_data.drop(columns=['target_variable'])\n","        y = self.sample_data['target_variable']\n","        with self.assertRaises(TypeError):\n","            handle_imbalanced_data(\"not a dataframe\", y)\n","        with self.assertRaises(TypeError):\n","            handle_imbalanced_data(X, \"not a series\")\n","        with self.assertRaises(ValueError):\n","            handle_imbalanced_data(X, y, method='invalid_method')\n","\n","    def test_handle_imbalanced_data_oversampling(self):\n","        X = self.sample_data.drop(columns=['target_variable'])\n","        y = self.sample_data['target_variable']\n","        X_resampled, y_resampled = handle_imbalanced_data(X, y, method='oversampling', random_state=42)\n","        self.assertGreaterEqual(y_resampled.value_counts().min(), y.value_counts().min())\n","\n","    def test_handle_imbalanced_data_undersampling(self):\n","        X = self.sample_data.drop(columns=['target_variable'])\n","        y = self.sample_data['target_variable']\n","        X_resampled, y_resampled = handle_imbalanced_data(X, y, method='undersampling', random_state=42)\n","        self.assertLessEqual(y_resampled.value_counts().max(), y.value_counts().max())\n","\n","if _name_ == \"_main_\":\n","    # Sample DataFrame (replace with your actual data loading)\n","    data = {\n","        'numerical_col1': [1, 5, 2, np.nan, 7, 100, 3],\n","        'numerical_col2': [0.1, 0.5, 0.2, 0.8, np.nan, 0.3, 0.6],\n","        'categorical_col1': ['A', 'B', 'A', 'C', 'B', 'A', np.nan],\n","        'categorical_col2': ['X', 'Y', 'X', 'Z', 'Y', 'X', 'Y'],\n","        'target_variable': [0, 1, 0, 1, 0, 1, 0]\n","    }\n","    df = pd.DataFrame(data)\n","\n","    print(\"Original DataFrame:\")\n","    print(df)\n","    print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","    # Separate target variable if it exists\n","    TARGET_COLUMN = 'target_variable'\n","    try:\n","        if TARGET_COLUMN in df.columns:\n","            X, y = df.drop(columns=[TARGET_COLUMN]), df[TARGET_COLUMN]\n","        else:\n","            X, y = df, None\n","\n","        # Handle missing values and scale/encode\n","        X_processed = preprocess_data(X)\n","        print(\"DataFrame after missing value handling, scaling, and encoding:\")\n","        print(X_processed)\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","        # Handle outliers in numerical columns\n","        numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n","        X_processed_no_outliers = handle_outliers_iqr(X_processed, numerical_cols)\n","        print(\"DataFrame after outlier handling (IQR method):\")\n","        print(X_processed_no_outliers)\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","        # Remove duplicate rows\n","        X_processed_unique = remove_duplicate_rows(X_processed_no_outliers)\n","        print(\"DataFrame after removing duplicate rows:\")\n","        print(X_processed_unique)\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","        # Handle imbalanced data if a target variable exists\n","        if y is not None:\n","            X_balanced, y_balanced = handle_imbalanced_data(X_processed_unique, y, method='oversampling', random_state=42)\n","            print(\"DataFrame after handling imbalanced data (oversampling):\")\n","            print(\"Resampled Features:\")\n","            print(X_balanced)\n","            print(\"\\nResampled Target:\")\n","            print(y_balanced.value_counts())\n","            print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","        # Run unit tests\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","        print(\"Running Unit Tests:\")\n","        suite = unittest.TestLoader().loadTestsFromTestCase(TestDataPreprocessing)\n","        unittest.TextTestRunner(verbosity=2).run(suite)\n","\n","    except (TypeError, ValueError, RuntimeError) as e:\n","        print(f\"An error occurred during processing: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Sx3FUf2i_dmj","executionInfo":{"status":"error","timestamp":1746373839794,"user_tz":-330,"elapsed":2738,"user":{"displayName":"Kavyashree MS","userId":"02983501451928927214"}},"outputId":"cc8b41bc-bfe9-4648-92c6-f46ce5adb7ed"},"execution_count":23,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '_name_' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2568f0fff30a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertLessEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m_name_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"_main_\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;31m# Sample DataFrame (replace with your actual data loading)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     data = {\n","\u001b[0;31mNameError\u001b[0m: name '_name_' is not defined"]}]}]}