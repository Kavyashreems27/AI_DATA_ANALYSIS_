{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyOxTQgxJ7XQimJdNGn3n9qO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Set plot style for better aesthetics\n","sns.set(style=\"whitegrid\")\n","\n","# Load the Titanic dataset from OpenML\n","titanic = fetch_openml(name='titanic', version=1, as_frame=True)\n","X = titanic.data\n","y = titanic.target\n","\n","# Display the shape of the dataset\n","print(f\"Dataset shape: {X.shape}\")\n","print(f\"Target distribution:\\n{y.value_counts()}\")\n","\n","# Identify numerical and categorical columns\n","numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# Define preprocessing steps for numerical features\n","numerical_pipeline = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n","    ('scaler', StandardScaler())  # Feature scaling\n","])\n","\n","# Define preprocessing steps for categorical features\n","categorical_pipeline = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n","    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding\n","])\n","\n","# Combine preprocessing steps using ColumnTransformer\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num', numerical_pipeline, numerical_cols),\n","    ('cat', categorical_pipeline, categorical_cols)\n","])\n","\n","# Define the complete pipeline\n","pipeline = Pipeline(steps=[\n","    ('preprocessing', preprocessor),\n","    ('feature_selection', VarianceThreshold(threshold=0.01)),  # Remove low-variance features\n","    ('classifier', RandomForestClassifier(random_state=42))  # Classification model\n","])\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","# Fit the pipeline on the training data\n","pipeline.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = pipeline.predict(X_test)\n","\n","# Evaluate the model's performance\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Retrieve feature names after preprocessing\n","# Note: This requires accessing the steps within the pipeline\n","# and may vary depending on the versions of scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Z_a6zkb-FUv","executionInfo":{"status":"ok","timestamp":1747044588113,"user_tz":-330,"elapsed":1470,"user":{"displayName":"Kavyashree MS","userId":"02983501451928927214"}},"outputId":"ca786ae4-6209-4d1d-eba0-56e78a52229a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset shape: (1309, 13)\n","Target distribution:\n","survived\n","0    809\n","1    500\n","Name: count, dtype: int64\n","\n","Model Accuracy: 0.9504\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.96      0.96       162\n","           1       0.94      0.93      0.93       100\n","\n","    accuracy                           0.95       262\n","   macro avg       0.95      0.95      0.95       262\n","weighted avg       0.95      0.95      0.95       262\n","\n"]}]}]}