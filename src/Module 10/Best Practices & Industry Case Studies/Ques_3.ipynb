{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyMjYci+KKfxu0NV6LtjAZRk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","import logging\n","import json\n","from sklearn.ensemble import IsolationForest\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","# Configure logging\n","logging.basicConfig(\n","    filename='fraud_detection.log',\n","    level=logging.INFO,\n","    format='%(asctime)s:%(levelname)s:%(message)s'\n",")\n","\n","# Load the financial dataset\n","try:\n","    df = pd.read_csv('financial_data.csv')  # Ensure this file exists in your working directory\n","    logging.info(\"Financial dataset loaded successfully.\")\n","except Exception as e:\n","    logging.error(f\"Error loading financial dataset: {e}\")\n","    raise\n","\n","# Define SLAs for data quality\n","SLAs = {\n","    'accuracy': 0.99,       # 99% of records should be accurate\n","    'completeness': 0.98,   # 98% of records should be complete\n","    'timeliness': 0.95      # 95% of data should be timely\n","}\n","\n","# Data Quality Checks\n","def data_quality_checks(data):\n","    total_records = len(data)\n","    missing_values = data.isnull().sum().sum()\n","    completeness = 1 - (missing_values / (total_records * data.shape[1]))\n","\n","    # For accuracy, assuming we have a method to verify accuracy; here we simulate it\n","    # In practice, this would involve comparing with a trusted source\n","    accuracy = np.random.uniform(0.95, 1.0)  # Placeholder for demonstration\n","\n","    # Timeliness check: assuming 'transaction_date' column exists\n","    if 'transaction_date' in data.columns:\n","        data['transaction_date'] = pd.to_datetime(data['transaction_date'], errors='coerce')\n","        timely_records = data['transaction_date'].notnull().sum()\n","        timeliness = timely_records / total_records\n","    else:\n","        timeliness = np.nan  # Cannot compute timeliness without 'transaction_date'\n","\n","    quality_metrics = {\n","        'accuracy': accuracy,\n","        'completeness': completeness,\n","        'timeliness': timeliness\n","    }\n","\n","    return quality_metrics\n","\n","# Perform data quality checks\n","quality_metrics = data_quality_checks(df)\n","logging.info(f\"Data Quality Metrics: {quality_metrics}\")\n","\n","# Compare with SLAs\n","def compare_with_sla(metrics, sla):\n","    for key in sla:\n","        if key in metrics and metrics[key] is not None:\n","            if metrics[key] < sla[key]:\n","                logging.warning(f\"{key.capitalize()} SLA not met: {metrics[key]:.2f} < {sla[key]}\")\n","            else:\n","                logging.info(f\"{key.capitalize()} SLA met: {metrics[key]:.2f} >= {sla[key]}\")\n","        else:\n","            logging.warning(f\"{key.capitalize()} metric not available for SLA comparison.\")\n","\n","compare_with_sla(quality_metrics, SLAs)\n","\n","# Data Preprocessing\n","# Drop rows with missing values\n","df_clean = df.dropna()\n","logging.info(f\"Data cleaned. Rows before: {len(df)}, after cleaning: {len(df_clean)}\")\n","\n","# Feature selection: assuming 'amount' and 'transaction_type' are relevant\n","features = ['amount']  # Add more relevant features as needed\n","if 'transaction_type' in df_clean.columns:\n","    # One-hot encode categorical variable\n","    df_encoded = pd.get_dummies(df_clean, columns=['transaction_type'], drop_first=True)\n","    features.extend([col for col in df_encoded.columns if col.startswith('transaction_type_')])\n","else:\n","    df_encoded = df_clean\n","\n","X = df_encoded[features]\n","\n","# Feature scaling\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Save the scaler for future use\n","joblib.dump(scaler, 'scaler.pkl')\n","\n","# Train Isolation Forest for anomaly detection\n","model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n","model.fit(X_scaled)\n","\n","# Save the model for future use\n","joblib.dump(model, 'fraud_detection_model.pkl')\n","\n","# Predict anomalies\n","df_encoded['anomaly'] = model.predict(X_scaled)\n","df_encoded['anomaly'] = df_encoded['anomaly'].map({1: 0, -1: 1})  # 1 for normal, -1 for anomaly\n","\n","# Evaluate model performance\n","# Assuming 'is_fraud' column exists as ground truth\n","if 'is_fraud' in df_encoded.columns:\n","    y_true = df_encoded['is_fraud']\n","    y_pred = df_encoded['anomaly']\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    accuracy = accuracy_score(y_true, y_pred)\n","\n","    logging.info(f\"Model Evaluation Metrics - Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, Accuracy: {accuracy:.2f}\")\n","else:\n","    logging.warning(\"Ground truth labels 'is_fraud' not available. Skipping model evaluation.\")\n","\n","# Visualize anomalies\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x='amount', y='anomaly', data=df_encoded, hue='anomaly', palette='coolwarm')\n","plt.title('Anomaly Detection in Financial Transactions')\n","plt.xlabel('Transaction Amount')\n","plt.ylabel('Anomaly')\n","plt.legend(title='Anomaly')\n","plt.tight_layout()\n","plt.savefig('anomaly_detection_plot.png')\n","plt.show()"],"metadata":{"id":"v8bnRiPDMUA-"},"execution_count":null,"outputs":[]}]}