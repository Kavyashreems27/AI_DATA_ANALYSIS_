{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyMOdcVMccHeZJO0mpom4X7d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","import logging\n","import json\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import StandardScaler\n","\n","# Configure logging\n","logging.basicConfig(\n","    filename='healthcare_data_validation.log',\n","    level=logging.INFO,\n","    format='%(asctime)s:%(levelname)s:%(message)s'\n",")\n","\n","# Load the healthcare dataset\n","try:\n","    df = pd.read_csv('healthcare_data.csv')  # Ensure this file exists in your working directory\n","    logging.info(\"Healthcare dataset loaded successfully.\")\n","except Exception as e:\n","    logging.error(f\"Error loading healthcare dataset: {e}\")\n","    raise\n","\n","# Define validation rules\n","def validate_data(data):\n","    issues = {}\n","\n","    # Rule 1: Check for missing values\n","    missing_values = data.isnull().sum()\n","    issues['missing_values'] = missing_values[missing_values > 0].to_dict()\n","\n","    # Rule 2: Check for duplicate records\n","    duplicate_count = data.duplicated().sum()\n","    issues['duplicate_records'] = duplicate_count\n","\n","    # Rule 3: Check for out-of-range values (example: age should be between 0 and 120)\n","    if 'age' in data.columns:\n","        out_of_range_age = data[(data['age'] < 0) | (data['age'] > 120)].shape[0]\n","        issues['out_of_range_age'] = out_of_range_age\n","\n","    # Rule 4: Check for inconsistent categorical entries (example: gender should be 'Male' or 'Female')\n","    if 'gender' in data.columns:\n","        valid_genders = ['Male', 'Female']\n","        invalid_genders = data[~data['gender'].isin(valid_genders)].shape[0]\n","        issues['invalid_genders'] = invalid_genders\n","\n","    return issues\n","\n","# Perform data validation\n","validation_issues = validate_data(df)\n","logging.info(f\"Data Validation Issues: {validation_issues}\")\n","\n","# Handle data quality issues\n","# Drop duplicate records\n","df = df.drop_duplicates()\n","logging.info(\"Duplicate records removed.\")\n","\n","# Handle missing values (example: drop rows with missing values)\n","df = df.dropna()\n","logging.info(\"Rows with missing values removed.\")\n","\n","# Remove out-of-range age values\n","if 'age' in df.columns:\n","    df = df[(df['age'] >= 0) & (df['age'] <= 120)]\n","    logging.info(\"Out-of-range age values removed.\")\n","\n","# Filter valid gender entries\n","if 'gender' in df.columns:\n","    df = df[df['gender'].isin(['Male', 'Female'])]\n","    logging.info(\"Invalid gender entries removed.\")\n","\n","# Encode categorical variables\n","if 'gender' in df.columns:\n","    df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n","\n","# Feature selection (example: selecting relevant features for prediction)\n","# Assume 'diagnosis', 'age', 'gender' are features and 'outcome' is the target variable\n","features = ['diagnosis', 'age', 'gender']\n","target = 'outcome'\n","\n","# Ensure all required columns are present\n","for col in features + [target]:\n","    if col not in df.columns:\n","        logging.error(f\"Required column '{col}' is missing from the dataset.\")\n","        raise ValueError(f\"Required column '{col}' is missing from the dataset.\")\n","\n","X = df[features]\n","y = df[target]\n","\n","# Handle categorical variables in features\n","X = pd.get_dummies(X, columns=['diagnosis'], drop_first=True)\n","\n","# Feature scaling\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Save the scaler for future use\n","joblib.dump(scaler, 'scaler.pkl')\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y, test_size=0.2, random_state=42\n",")\n","\n","# Train a Random Forest classifier\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Save the trained model for future use\n","joblib.dump(model, 'healthcare_prediction_model.pkl')\n","\n","# Evaluate the model\n","y_pred = model.predict(X_test)\n","report = classification_report(y_test, y_pred, output_dict=True)\n","logging.info(f\"Model Evaluation Report:\\n{json.dumps(report, indent=2)}\")\n","\n","# Visualize feature importance\n","importances = model.feature_importances_\n","feature_names = X.columns\n","feature_importance_df = pd.DataFrame({\n","    'Feature': feature_names,\n","    'Importance': importances\n","}).sort_values(by='Importance', ascending=False)\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n","plt.title('Feature Importance')\n","plt.tight_layout()\n","plt.savefig('feature_importance.png')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"vW9ZKOIXPWt2","executionInfo":{"status":"error","timestamp":1747066048567,"user_tz":-330,"elapsed":25,"user":{"displayName":"Kavyashree MS","userId":"02983501451928927214"}},"outputId":"47af797b-a244-49cd-8936-cc245c5ff17f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Error loading healthcare dataset: [Errno 2] No such file or directory: 'healthcare_data.csv'\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'healthcare_data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-12be8d793fcc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load the healthcare dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'healthcare_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure this file exists in your working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Healthcare dataset loaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'healthcare_data.csv'"]}]}]}