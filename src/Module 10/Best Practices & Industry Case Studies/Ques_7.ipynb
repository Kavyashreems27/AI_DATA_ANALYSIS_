{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyMQu5c4iewk/a6K+6iq/3Gd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from surprise import Dataset, Reader, SVD\n","from surprise.model_selection import train_test_split\n","from surprise.accuracy import rmse\n","import mlflow\n","import mlflow.sklearn\n","import os\n","\n","# Set the MLflow tracking URI (default is local file-based)\n","mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")  # Ensure MLflow server is running at this URI\n","\n","# Set or create an MLflow experiment\n","experiment_name = \"Ecommerce_Recommendation_Engine\"\n","mlflow.set_experiment(experiment_name)\n","\n","# Load the sample e-commerce dataset\n","# For demonstration, we'll create a synthetic dataset\n","# In practice, replace this with loading your actual dataset\n","data_dict = {\n","    'user_id': np.random.randint(1, 100, 1000),\n","    'item_id': np.random.randint(1, 500, 1000),\n","    'rating': np.random.randint(1, 6, 1000)\n","}\n","df = pd.DataFrame(data_dict)\n","\n","# Define a Reader and load the data into Surprise Dataset\n","reader = Reader(rating_scale=(1, 5))\n","data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n","\n","# Split the dataset into training and testing sets\n","trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# Define model parameters\n","model_params = {\n","    \"n_factors\": 100,\n","    \"n_epochs\": 20,\n","    \"lr_all\": 0.005,\n","    \"reg_all\": 0.02\n","}\n","\n","# Start an MLflow run\n","with mlflow.start_run(run_name=\"SVD_Collaborative_Filtering\") as run:\n","    # Initialize and train the SVD model\n","    model = SVD(**model_params)\n","    model.fit(trainset)\n","\n","    # Make predictions on the test set\n","    predictions = model.test(testset)\n","\n","    # Calculate evaluation metric (RMSE)\n","    test_rmse = rmse(predictions, verbose=False)\n","\n","    # Log parameters and metrics to MLflow\n","    mlflow.log_params(model_params)\n","    mlflow.log_metric(\"test_rmse\", test_rmse)\n","\n","    # Log the model\n","    # Note: Surprise models are not directly supported by mlflow.sklearn\n","    # We'll save the model manually and log it as an artifact\n","    model_path = \"svd_model.pkl\"\n","    import joblib\n","    joblib.dump(model, model_path)\n","    mlflow.log_artifact(model_path)\n","\n","    print(f\"Run completed with ID: {run.info.run_id}\")\n","    print(f\"Logged metrics:\\n  - Test RMSE: {test_rmse:.4f}\")\n","    print(f\"Model and metrics are logged under the experiment: '{experiment_name}'\")\n","\n","    # Clean up the saved model file\n","    os.remove(model_path)"],"metadata":{"id":"mITIi6aJXari"},"execution_count":null,"outputs":[]}]}