{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyNiQ5THA6T7OakcJ1Vuwr3L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import joblib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import StandardScaler\n","import json\n","import logging\n","import os\n","\n","# Configure logging\n","logging.basicConfig(\n","    filename='model_monitoring.log',\n","    level=logging.INFO,\n","    format='%(asctime)s:%(levelname)s:%(message)s'\n",")\n","\n","# Load trained model and scaler\n","try:\n","    model = joblib.load('model.pkl')\n","    scaler = joblib.load('scaler.pkl')\n","except Exception as e:\n","    logging.error(f\"Error loading model or scaler: {e}\")\n","    raise\n","\n","# Load new data\n","try:\n","    new_data = pd.read_csv('new_data.csv')  # Make sure this file exists\n","except Exception as e:\n","    logging.error(f\"Error loading new data: {e}\")\n","    raise\n","\n","# Preprocess new data\n","def preprocess_data(df):\n","    df = df.dropna()\n","    X = df.drop('target', axis=1)\n","    y = df['target']\n","    X_scaled = scaler.transform(X)\n","    return X_scaled, y\n","\n","try:\n","    X_new, y_new = preprocess_data(new_data)\n","except Exception as e:\n","    logging.error(f\"Error during preprocessing: {e}\")\n","    raise\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_new)\n","\n","def calculate_metrics(y_true, y_pred):\n","    return {\n","        'accuracy': accuracy_score(y_true, y_pred),\n","        'precision': precision_score(y_true, y_pred, zero_division=0),\n","        'recall': recall_score(y_true, y_pred, zero_division=0),\n","        'f1_score': f1_score(y_true, y_pred, zero_division=0)\n","    }\n","\n","current_metrics = calculate_metrics(y_new, y_pred)\n","logging.info(f\"Current Metrics: {current_metrics}\")\n","\n","# Load baseline metrics\n","try:\n","    with open('baseline_metrics.json', 'r') as f:\n","        baseline_metrics = json.load(f)\n","except Exception as e:\n","    logging.warning(\"Baseline metrics not found. Assuming current metrics as baseline.\")\n","    baseline_metrics = current_metrics\n","\n","# Drift detection\n","def detect_drift(current, baseline, threshold=0.05):\n","    drift = False\n","    for metric in current:\n","        if abs(current[metric] - baseline[metric]) > threshold:\n","            logging.warning(f\"Drift detected in {metric}: baseline={baseline[metric]}, current={current[metric]}\")\n","            drift = True\n","    return drift\n","\n","drift_found = detect_drift(current_metrics, baseline_metrics)\n","if drift_found:\n","    logging.warning(\"Performance drift detected.\")\n","else:\n","    logging.info(\"No drift detected.\")\n","\n","# Plot metrics comparison\n","df_plot = pd.DataFrame([baseline_metrics, current_metrics], index=['Baseline', 'Current'])\n","df_plot.plot(kind='bar')\n","plt.title(\"Performance Metrics Comparison\")\n","plt.ylabel(\"Score\")\n","plt.ylim(0, 1)\n","plt.xticks(rotation=0)\n","plt.tight_layout()\n","plt.savefig(\"performance_comparison.png\")\n","plt.show()\n","\n","# Optional: update baseline (uncomment below to enable)\n","# with open('baseline_metrics.json', 'w') as f:\n","#     json.dump(current_metrics, f)"],"metadata":{"id":"iHifvpW2GNqV"},"execution_count":null,"outputs":[]}]}