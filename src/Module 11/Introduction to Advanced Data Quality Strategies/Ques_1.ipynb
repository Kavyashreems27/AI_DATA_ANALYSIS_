{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyNnC390lQuDnN2wj8lj7KRH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import logging\n","import json\n","import os\n","from datetime import datetime\n","from sklearn.ensemble import IsolationForest\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Configure logging\n","logging.basicConfig(\n","    filename='advanced_data_quality.log',\n","    level=logging.INFO,\n","    format='%(asctime)s:%(levelname)s:%(message)s'\n",")\n","\n","# Load the dataset\n","try:\n","    df = pd.read_csv('your_dataset.csv')  # Replace with your dataset path\n","    logging.info(\"Dataset loaded successfully.\")\n","except Exception as e:\n","    logging.error(f\"Error loading dataset: {e}\")\n","    raise\n","\n","# Data Profiling\n","def data_profiling(data):\n","    profile = {\n","        'shape': data.shape,\n","        'columns': data.columns.tolist(),\n","        'dtypes': data.dtypes.apply(lambda x: x.name).to_dict(),\n","        'missing_values': data.isnull().sum().to_dict(),\n","        'duplicate_records': int(data.duplicated().sum()),\n","        'summary_statistics': data.describe(include='all').to_dict()\n","    }\n","    return profile\n","\n","profiling_report = data_profiling(df)\n","with open('data_profiling_report.json', 'w') as f:\n","    json.dump(profiling_report, f, indent=4)\n","logging.info(\"Data profiling completed and report saved.\")\n","\n","# Data Validation Rules\n","def validate_data(data):\n","    issues = {}\n","\n","    # Rule 1: Check for missing values\n","    missing = data.isnull().sum()\n","    issues['missing_values'] = missing[missing > 0].to_dict()\n","\n","    # Rule 2: Check for duplicate records\n","    duplicates = data.duplicated().sum()\n","    issues['duplicate_records'] = int(duplicates)\n","\n","    # Rule 3: Check for out-of-range values (example: age should be between 0 and 120)\n","    if 'age' in data.columns:\n","        out_of_range = data[(data['age'] < 0) | (data['age'] > 120)].shape[0]\n","        issues['out_of_range_age'] = int(out_of_range)\n","\n","    # Rule 4: Check for invalid categorical entries (example: gender should be 'Male' or 'Female')\n","    if 'gender' in data.columns:\n","        valid_genders = ['Male', 'Female']\n","        invalid_genders = data[~data['gender'].isin(valid_genders)].shape[0]\n","        issues['invalid_genders'] = int(invalid_genders)\n","\n","    return issues\n","\n","validation_issues = validate_data(df)\n","with open('data_validation_issues.json', 'w') as f:\n","    json.dump(validation_issues, f, indent=4)\n","logging.info(\"Data validation completed and issues report saved.\")\n","\n","# Data Cleaning\n","def clean_data(data):\n","    # Drop duplicate records\n","    data = data.drop_duplicates()\n","\n","    # Handle missing values (example: drop rows with missing values)\n","    data = data.dropna()\n","\n","    # Remove out-of-range age values\n","    if 'age' in data.columns:\n","        data = data[(data['age'] >= 0) & (data['age'] <= 120)]\n","\n","    # Filter valid gender entries\n","    if 'gender' in data.columns:\n","        data = data[data['gender'].isin(['Male', 'Female'])]\n","\n","    return data\n","\n","df_cleaned = clean_data(df)\n","logging.info(\"Data cleaning completed.\")\n","\n","# Anomaly Detection using Isolation Forest\n","def detect_anomalies(data, features):\n","    # Encode categorical variables\n","    for col in features:\n","        if data[col].dtype == 'object':\n","            le = LabelEncoder()\n","            data[col] = le.fit_transform(data[col])\n","\n","    iso_forest = IsolationForest(contamination=0.01, random_state=42)\n","    data['anomaly'] = iso_forest.fit_predict(data[features])\n","    anomalies = data[data['anomaly'] == -1]\n","    return anomalies\n","\n","# Specify features for anomaly detection\n","anomaly_features = ['age']  # Add more numerical features as needed\n","anomalies = detect_anomalies(df_cleaned.copy(), anomaly_features)\n","anomalies.to_csv('anomalies.csv', index=False)\n","logging.info(f\"Anomaly detection completed. {anomalies.shape[0]} anomalies found and saved.\")\n","\n","# Generate Data Quality Report\n","def generate_report(profiling, validation, anomalies):\n","    report = {\n","        'profiling': profiling,\n","        'validation_issues': validation,\n","        'anomalies_detected': anomalies.shape[0],\n","        'report_generated_at': datetime.now().isoformat()\n","    }\n","    with open('data_quality_report.json', 'w') as f:\n","        json.dump(report, f, indent=4)\n","    logging.info(\"Data quality report generated and saved.\")\n","\n","generate_report(profiling_report, validation_issues, anomalies)\n","\n","# Visualizations\n","def visualize_data(data):\n","    # Histogram of age\n","    if 'age' in data.columns:\n","        plt.figure(figsize=(10, 6))\n","        sns.histplot(data['age'], bins=30, kde=True)\n","        plt.title('Age Distribution')\n","        plt.xlabel('Age')\n","        plt.ylabel('Frequency')\n","        plt.tight_layout()\n","        plt.savefig('age_distribution.png')\n","        plt.close()\n","        logging.info(\"Age distribution plot saved.\")\n","\n","    # Bar plot of gender\n","    if 'gender' in data.columns:\n","        plt.figure(figsize=(6, 4))\n","        sns.countplot(x='gender', data=data)\n","        plt.title('Gender Count')\n","        plt.xlabel('Gender')\n","        plt.ylabel('Count')\n","        plt.tight_layout()\n","        plt.savefig('gender_count.png')\n","        plt.close()\n","        logging.info(\"Gender count plot saved.\")\n","\n","visualize_data(df_cleaned)"],"metadata":{"id":"3MscrM1gZkDY","executionInfo":{"status":"error","timestamp":1747068558903,"user_tz":-330,"elapsed":118,"user":{"displayName":"Kavyashree MS","userId":"02983501451928927214"}},"outputId":"90d5b569-1c6b-4447-e456-431640dfd363","colab":{"base_uri":"https://localhost:8080/","height":391}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Error loading dataset: [Errno 2] No such file or directory: 'your_dataset.csv'\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'your_dataset.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-012d1fee8613>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with your dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset loaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0mskiprows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0mskipfooter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0mnrows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0mna_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m \u001b[0;31m# iterator=True -> TextFileReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m def read_csv(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The value of index_col couldn't be 'True'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_index_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m                 \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index_col\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m         \u001b[0mna_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_na_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             \u001b[0mna_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_values\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mna_fvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_floatify_na_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;31m# Convert BytesIO or file objects passed with an encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"]}]}]}