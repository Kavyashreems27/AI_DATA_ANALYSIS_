{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1azhh6D8JdIS6lAU3feMmwaDIJ0fU9nRi","authorship_tag":"ABX9TyMr/o1jBnixulFl3lf+LI05"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Autoencoders for Anomaly Detection\n","\n","# Step 1: Import Necessary Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_diabetes\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras import regularizers\n","import tensorflow as tf\n","\n","# Step 2: Load the Diabetes Dataset\n","diabetes = load_diabetes()\n","data = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n","data['target'] = diabetes.target\n","\n","# Step 3: Select Features for Analysis\n","selected_features = ['age', 'bmi', 'bp']\n","df = data[selected_features].copy()\n","\n","# Step 4: Standardize the Features\n","scaler = StandardScaler()\n","df_scaled = scaler.fit_transform(df)\n","\n","# Step 5: Split Data into Training and Test Sets\n","X_train, X_test = train_test_split(df_scaled, test_size=0.2, random_state=42)\n","\n","# Step 6: Define the Autoencoder Model\n","input_dim = X_train.shape[1]\n","encoding_dim = 2  # Size of the encoded representation\n","\n","input_layer = Input(shape=(input_dim,))\n","encoder = Dense(encoding_dim, activation=\"relu\",\n","                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n","decoder = Dense(input_dim, activation='linear')(encoder)\n","autoencoder = Model(inputs=input_layer, outputs=decoder)\n","\n","# Step 7: Compile the Model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Step 8: Train the Autoencoder\n","history = autoencoder.fit(X_train, X_train,\n","                          epochs=100,\n","                          batch_size=16,\n","                          shuffle=True,\n","                          validation_data=(X_test, X_test),\n","                          verbose=0)\n","\n","# Step 9: Calculate Reconstruction Error on the Test Set\n","X_test_pred = autoencoder.predict(X_test)\n","mse = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n","\n","# Step 10: Determine Threshold for Anomaly Detection\n","threshold = np.percentile(mse, 95)  # 95th percentile\n","print(\"Reconstruction error threshold:\", threshold)\n","\n","# Step 11: Identify Anomalies\n","anomalies = mse > threshold\n","print(\"Number of anomalies detected:\", np.sum(anomalies))\n","\n","# Step 12: Visualize Anomalies\n","plt.figure(figsize=(12, 6))\n","plt.scatter(X_test[:, 1], X_test[:, 2], c=anomalies, cmap='coolwarm')\n","plt.xlabel('BMI (standardized)')\n","plt.ylabel('BP (standardized)')\n","plt.title('Anomaly Detection using Autoencoder')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"ORKQwK4tFr1q"},"execution_count":null,"outputs":[]}]}